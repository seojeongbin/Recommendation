{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> - sr-gnn 은 session based recommend gnn 의 준말\n",
    ">    - session은 사용자 기록 로그 같은 느낌임\n",
    ">    - 기존은 global하게는 추천이 가능하였지만 local 하게는 어려웠음 (즉 현시점에서 관심갖고 있는것이 무엇인가)\n",
    ">    - session 단위로 처리함으로써 현재단계에서 관심가질법한 상품 추천도 가능하게됨\n",
    "\n",
    "주석은 영어로 작성하려고 노력함"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SR-GNN exercise \n",
    "- used data : kaggle competition (https://www.kaggle.com/retailrocket/ecommerce-dataset)\n",
    "- reference : https://colab.research.google.com/drive/1XwQ0njqSZL8vbHJMnRRHlH4ar0kYYFVz?usp=sharing#scrollTo=MKM4wAYG9ssq\n",
    "- after-report : https://velog.io/@seojeongbin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Python built-in libraries\n",
    "import copy\n",
    "import pickle\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "# Import pip libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "\n",
    "# Import torch packages\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils import data\n",
    "\n",
    "# Import PyG packages\n",
    "import torch_geometric as pyg\n",
    "import torch_geometric.data as pyg_data\n",
    "from torch_geometric.typing import Adj, OptTensor\n",
    "import torch_sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       timestamp  visitorid event  itemid  transactionid\n",
      "0  1433221332117     257597  view  355908            NaN\n",
      "1  1433224214164     992329  view  248676            NaN\n",
      "2  1433221999827     111016  view  318965            NaN\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "2756101"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_path = r'C:\\Users\\SeoJeongBin\\Desktop\\Code\\Recommendation\\GNN\\data\\SR-GNN\\events.csv\\events.csv'\n",
    "events_df = pd.read_csv(data_path)\n",
    "print(events_df.head(3))\n",
    "len(events_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['view' 'addtocart' 'transaction']\n",
      "[   nan  4000. 11117. ...  4385. 13872. 17579.]\n"
     ]
    }
   ],
   "source": [
    "print(events_df['event'].unique()) # 3types\n",
    "print(events_df['transactionid'].unique()) # unique type (only for transaction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "466867\n",
      "0\n",
      "1407579\n"
     ]
    }
   ],
   "source": [
    "print(min(events_df['itemid']))\n",
    "print(max(events_df['itemid']))\n",
    "print(min(events_df['visitorid']))\n",
    "print(max(events_df['visitorid']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separating log data into sessions\n",
    "- what we do in the cell below contains 4 steps\n",
    "- event == view 인 경우만 처리\n",
    "- 방문 2회 이상 고객 대상 분석\n",
    "- session을 두시간으로 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1433221337106</td>\n",
       "      <td>951259</td>\n",
       "      <td>view</td>\n",
       "      <td>367447</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756096</th>\n",
       "      <td>1438398785939</td>\n",
       "      <td>591435</td>\n",
       "      <td>view</td>\n",
       "      <td>261427</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756097</th>\n",
       "      <td>1438399813142</td>\n",
       "      <td>762376</td>\n",
       "      <td>view</td>\n",
       "      <td>115946</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756098</th>\n",
       "      <td>1438397820527</td>\n",
       "      <td>1251746</td>\n",
       "      <td>view</td>\n",
       "      <td>78144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756099</th>\n",
       "      <td>1438398530703</td>\n",
       "      <td>1184451</td>\n",
       "      <td>view</td>\n",
       "      <td>283392</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756100</th>\n",
       "      <td>1438400163914</td>\n",
       "      <td>199536</td>\n",
       "      <td>view</td>\n",
       "      <td>152913</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2664312 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  visitorid event  itemid  transactionid\n",
       "0        1433221332117     257597  view  355908            NaN\n",
       "1        1433224214164     992329  view  248676            NaN\n",
       "2        1433221999827     111016  view  318965            NaN\n",
       "3        1433221955914     483717  view  253185            NaN\n",
       "4        1433221337106     951259  view  367447            NaN\n",
       "...                ...        ...   ...     ...            ...\n",
       "2756096  1438398785939     591435  view  261427            NaN\n",
       "2756097  1438399813142     762376  view  115946            NaN\n",
       "2756098  1438397820527    1251746  view   78144            NaN\n",
       "2756099  1438398530703    1184451  view  283392            NaN\n",
       "2756100  1438400163914     199536  view  152913            NaN\n",
       "\n",
       "[2664312 rows x 5 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. filter only the 'view' events\n",
    "events_df_filtered = events_df.loc[events_df['event']=='view',:] # loc 내부 순서 실수 주의\n",
    "events_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "timestamp      visitorid  event  itemid  transactionid\n",
       "1438650539084  951289     view   5190    NaN              3\n",
       "1435308445514  1152713    view   427254  NaN              3\n",
       "1440044157440  1177355    view   161623  NaN              2\n",
       "1434468685577  618116     view   73917   NaN              2\n",
       "1439830202573  515669     view   56500   NaN              2\n",
       "                                                         ..\n",
       "1434504724447  1270836    view   53959   NaN              1\n",
       "1434504725643  562087     view   351415  NaN              1\n",
       "1434504726584  1326048    view   316575  NaN              1\n",
       "1434504727158  794304     view   293458  NaN              1\n",
       "1442545187788  1287495    view   98299   NaN              1\n",
       "Length: 2664218, dtype: int64"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. filter out visitors with single clicks\n",
    "visit_counts_per_visitor = events_df_filtered.value_counts(dropna=False)\n",
    "visit_counts_per_visitor # 중복횟수를 우측에 카운트되게 나옴, 자동 내림차순(dropna=false는 nan값을 무시하지 않게 해줌)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1150086    6479\n",
       "530559     3623\n",
       "895999     2368\n",
       "152963     2304\n",
       "163561     2194\n",
       "           ... \n",
       "908147        1\n",
       "258979        1\n",
       "551045        1\n",
       "218233        1\n",
       "1184451       1\n",
       "Name: visitorid, Length: 1404179, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visit_counts_per_visitor = events_df_filtered['visitorid'].value_counts(dropna=False)\n",
    "visit_counts_per_visitor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timestamp</th>\n",
       "      <th>visitorid</th>\n",
       "      <th>event</th>\n",
       "      <th>itemid</th>\n",
       "      <th>transactionid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1433221332117</td>\n",
       "      <td>257597</td>\n",
       "      <td>view</td>\n",
       "      <td>355908</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1433224214164</td>\n",
       "      <td>992329</td>\n",
       "      <td>view</td>\n",
       "      <td>248676</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1433221999827</td>\n",
       "      <td>111016</td>\n",
       "      <td>view</td>\n",
       "      <td>318965</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1433221955914</td>\n",
       "      <td>483717</td>\n",
       "      <td>view</td>\n",
       "      <td>253185</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1433224086234</td>\n",
       "      <td>972639</td>\n",
       "      <td>view</td>\n",
       "      <td>22556</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756092</th>\n",
       "      <td>1438398473572</td>\n",
       "      <td>709520</td>\n",
       "      <td>view</td>\n",
       "      <td>104512</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756094</th>\n",
       "      <td>1438399289446</td>\n",
       "      <td>701750</td>\n",
       "      <td>view</td>\n",
       "      <td>296172</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756095</th>\n",
       "      <td>1438400574346</td>\n",
       "      <td>289041</td>\n",
       "      <td>view</td>\n",
       "      <td>156947</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756098</th>\n",
       "      <td>1438397820527</td>\n",
       "      <td>1251746</td>\n",
       "      <td>view</td>\n",
       "      <td>78144</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2756100</th>\n",
       "      <td>1438400163914</td>\n",
       "      <td>199536</td>\n",
       "      <td>view</td>\n",
       "      <td>152913</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1656582 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             timestamp  visitorid event  itemid  transactionid\n",
       "0        1433221332117     257597  view  355908            NaN\n",
       "1        1433224214164     992329  view  248676            NaN\n",
       "2        1433221999827     111016  view  318965            NaN\n",
       "3        1433221955914     483717  view  253185            NaN\n",
       "5        1433224086234     972639  view   22556            NaN\n",
       "...                ...        ...   ...     ...            ...\n",
       "2756092  1438398473572     709520  view  104512            NaN\n",
       "2756094  1438399289446     701750  view  296172            NaN\n",
       "2756095  1438400574346     289041  view  156947            NaN\n",
       "2756098  1438397820527    1251746  view   78144            NaN\n",
       "2756100  1438400163914     199536  view  152913            NaN\n",
       "\n",
       "[1656582 rows x 5 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visitors_with_significant_visits = visit_counts_per_visitor[visit_counts_per_visitor > 1].index # 방문을 1번 넘게한 user\n",
    "events_df_filtered = events_df_filtered[events_df_filtered['visitorid'].isin(visitors_with_significant_visits)] # visitorid가 visitors_with_significant_visits 리스트에 속하는 경우만 반환\n",
    "events_df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1656582it [02:24, 11466.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 396449 visitors left.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's group events and their timing data.\n",
    "visits_by_visitors = {}\n",
    "for _, row in enumerate(tqdm(events_df_filtered.iterrows())): # tqdm : 진행률 보여줌 / iterrows : df행 단위로 받아올 수 있음. 튜플임 (행넘버, 내용 시리즈 객체)\n",
    "    timestamp, visitorid, event, itemid, transactionid = row[1].values\n",
    "\n",
    "    if visitorid not in visits_by_visitors:\n",
    "        visits_by_visitors[visitorid] = {'itemids': [], 'timestamps': []} # 전체 df돌면서 visitor마다 딕셔너리 키 생성해주고\n",
    "    visits_by_visitors[visitorid]['itemids'].append(itemid)\n",
    "    visits_by_visitors[visitorid]['timestamps'].append(timestamp)\n",
    "\n",
    "print(f'There are {len(visits_by_visitors)} visitors left.') # len(events_df_filtered['visitorid'].unique()) 걍 이거랑 똑같음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "There are 396449 sessions.\n"
     ]
    }
   ],
   "source": [
    "# We will separate sessions by 2 hours.\n",
    "delay = 2 * 3600 * 1000\n",
    "\n",
    "# Let's group events from visitors into sessions.\n",
    "sessions_by_visitors = {}\n",
    "for visitorid, visitor_dict in visits_by_visitors.items():\n",
    "    sessions = [[]]\n",
    "    events_sorted = sorted(zip(visitor_dict['timestamps'], visitor_dict['itemids']))\n",
    "    for i in range(len(events_sorted) - 1):\n",
    "        sessions[-1].append(events_sorted[i][1])\n",
    "        if (events_sorted[i+1][0] - events_sorted[i][0]) > delay:\n",
    "            sessions.append([])\n",
    "    sessions[-1].append(events_sorted[len(events_sorted) - 1][1])\n",
    "    sessions_by_visitors[visitorid] = sessions\n",
    "\n",
    "# print(sessions_by_visitors) => 이용자별로 session을 만드는과정임 고객 A : [[1시],[2시,2시10분,2시15분]] 이런느낌\n",
    "print()\n",
    "print(f'There are {len(sessions_by_visitors)} sessions.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting train and test dataset\n",
    "- now let's split data (train, valid, test) by user ids\n",
    "    - each user will only be found in one of the three splits\n",
    "    - We split like this because the model may 'cheat' from partial sessions of a user during training and use that information during test time.\n",
    "- 원래 추천시스템에서 데이터 분할하는게 일반적인 방법이랑 조금 다름\n",
    "    - 참고 : https://data-newbie.tistory.com/842"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, val, and test visitors: (317159, 79290, 0)\n"
     ]
    }
   ],
   "source": [
    "# Adjsut sampling rate ([0, 1]) to generate smaller datasets.\n",
    "# Setting `sampling_rate` to 1 will lead to a full dataset split.\n",
    "sampling_rate = 1\n",
    "seed = 42 # random seed for reproducibility\n",
    "all_visitors = list(sessions_by_visitors.keys()) # 실수주의 : key()가 아니라 keys()임\n",
    "random.Random(seed).shuffle(all_visitors)\n",
    "\n",
    "num_train = int(len(all_visitors) * 0.8 * sampling_rate)\n",
    "num_val = int(len(all_visitors) * 0.8 * sampling_rate)\n",
    "num_test = int(len(all_visitors) * 0.8 * sampling_rate)\n",
    "\n",
    "train_visitors = all_visitors[:num_train]\n",
    "val_visitors = all_visitors[num_train : num_train+num_val]\n",
    "test_visitors = all_visitors[num_train+num_val:num_train+num_val+num_test]\n",
    "\n",
    "print(f'train, val, and test visitors: {len(train_visitors), len(val_visitors), len(test_visitors)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- let's check the size of each split and pickle the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 위에는 user만 하였으니 session도 train val test 나누어준다\n",
    "# each session => subsession (논문이 이런식으로 했음)\n",
    "def extract_subsessions(sessions):\n",
    "    \"\"\"Extracts all partial sessions from the sessions given.\n",
    "\n",
    "    For example, a session (1, 2, 3) should be augemnted to produce two\n",
    "    separate sessions (1, 2) and (1, 2, 3).\n",
    "    \"\"\"\n",
    "    all_sessions = []\n",
    "    for session in sessions:\n",
    "        for i in range(1, len(session)):\n",
    "            all_sessions.append(session[:i+1])\n",
    "    return all_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train, val, and test sessions: (781928, 188217, 0)\n"
     ]
    }
   ],
   "source": [
    "# Get sessions of each visitor, generate subsessions of each session, and put all the generated subsessions into right splits.\n",
    "# We generate subsessions according to the dataset generation policy suggested by the original SR-GNN paper.\n",
    "train_sessions, val_sessions, test_sessions = [], [], []\n",
    "for visitor in train_visitors:\n",
    "    train_sessions.extend(extract_subsessions(sessions_by_visitors[visitor]))\n",
    "for visitor in val_visitors:\n",
    "    val_sessions.extend(extract_subsessions(sessions_by_visitors[visitor]))\n",
    "for visitor in test_visitors:\n",
    "    test_sessions.extend(extract_subsessions(sessions_by_visitors[visitor]))\n",
    "    \n",
    "print(f'train, val, and test sessions: {len(train_sessions), len(val_sessions), len(test_sessions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pipeline (여기부터 밑에까지는 진짜 모르겠다)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphDataset(pyg_data.InMemoryDataset):\n",
    "    def __init__(self, root, file_name, transform=None, pre_transform=None):\n",
    "        self.file_name = file_name\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        return [f'{self.file_name}.txt']\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        return [f'{self.file_name}.pt']\n",
    "\n",
    "    def download(self):\n",
    "        pass\n",
    "\n",
    "    def process(self):\n",
    "        raw_data_file = f'{self.raw_dir}/{self.raw_file_names[0]}'\n",
    "        with open(raw_data_file, 'rb') as f:\n",
    "            sessions = pickle.load(f)\n",
    "        data_list = []\n",
    "\n",
    "        for session in sessions:\n",
    "            session, y = session[:-1], session[-1]\n",
    "            codes, uniques = pd.factorize(session)\n",
    "            senders, receivers = codes[:-1], codes[1:]\n",
    "\n",
    "            # Build Data instance\n",
    "            edge_index = torch.tensor([senders, receivers], dtype=torch.long)\n",
    "            x = torch.tensor(uniques, dtype=torch.long).unsqueeze(1)\n",
    "            y = torch.tensor([y], dtype=torch.long)\n",
    "            data_list.append(pyg_data.Data(x=x, edge_index=edge_index, y=y))\n",
    "\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Design\n",
    "our gated session graph layer has two main parts\n",
    "- 1. message propagation to create an adjacency matrix(self.propage)\n",
    "- 2. the grou cell(self.gru)\n",
    "    - we will put these inside the forward() function\n",
    "    - We only use one layer for our GatedSessionGraphConv implementation for simplicity. Also, our sessions have average length < 5, so we do not need a large receptive field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 메모\n",
    "'''\n",
    "이해하기 상당히 어려운것들이 몇가지 있음\n",
    "- channel 의미\n",
    "- gated~가 무엇인지\n",
    "- propagate가 무엇인지\n",
    "- aggregate가 무엇인지\n",
    "일단 검색결과 gnn 중에서도 pyg에 해당하는 사항, 이거는 rnn 관련이란걸 알게됨. gatedgnn이 gnn += rnn인듯. gru는 lstm 이후 나온 장기기억 방법..음..\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GatedSessionGraphConv(pyg.nn.MessagePassing):\n",
    "    def __init__(self, out_channels, aggr : str = 'add', **kwargs):\n",
    "        super().__init__(aggr=aggr, **kwargs)\n",
    "        \n",
    "        self.out_channels = out_channels # channel이 뭘까..\n",
    "        self.gru = torch.nn.GRUCell(out_channels, out_channels, bias=False)\n",
    "        \n",
    "    def forward(self, x, edge_index):\n",
    "        m = self.propage(edge_index, x=x, size=None)\n",
    "        x = self.gru(m,x)\n",
    "        return x\n",
    "    \n",
    "    def message(self, x_j): # 이거 네이밍에 주의해야한다는 것 같았음\n",
    "        return x_j\n",
    "    \n",
    "    def message_and_aggregate(self, adj_t, x):\n",
    "        return matmul(adj_t, x, reduce=self.aggr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SRGNN(nn.Module):\n",
    "    def __init__(self, hidden_size, n_items):\n",
    "        super(SRGNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.n_items = n_items\n",
    "\n",
    "        self.embedding = nn.Embedding(self.n_items, self.hidden_size)\n",
    "        self.gated = GatedSessionGraphConv(self.hidden_size) # 저위에서 선언하고 이걸 객체로 받은느낌인데.. 다시한번 passing 대해서 두개 글 읽어보기\n",
    "\n",
    "        self.q = nn.Linear(self.hidden_size, 1)\n",
    "        self.W_1 = nn.Linear(self.hidden_size, self.hidden_size, bias=False)\n",
    "        self.W_2 = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.W_3 = nn.Linear(2 * self.hidden_size, self.hidden_size, bias=False)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        stdv = 1.0 / math.sqrt(self.hidden_size)\n",
    "        for weight in self.parameters():\n",
    "            weight.data.uniform_(-stdv, stdv)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index, batch_map = data.x, data.edge_index, data.batch\n",
    "\n",
    "        # (0)\n",
    "        embedding = self.embedding(x).squeeze()\n",
    "\n",
    "        # (1)-(5)\n",
    "        v_i = self.gated(embedding, edge_index)\n",
    "\n",
    "        # Divide nodes by session\n",
    "        # For the detailed explanation of what is happening below, please refer\n",
    "        # to the Medium blog post.\n",
    "        sections = list(torch.bincount(batch_map).cpu())\n",
    "        v_i_split = torch.split(v_i, sections)\n",
    "\n",
    "        v_n, v_n_repeat = [], []\n",
    "        for session in v_i_split:\n",
    "            v_n.append(session[-1])\n",
    "            v_n_repeat.append(\n",
    "                session[-1].view(1, -1).repeat(session.shape[0], 1))\n",
    "        v_n, v_n_repeat = torch.stack(v_n), torch.cat(v_n_repeat, dim=0)\n",
    "\n",
    "        q1 = self.W_1(v_n_repeat)\n",
    "        q2 = self.W_2(v_i)\n",
    "\n",
    "        # (6)\n",
    "        alpha = self.q(F.sigmoid(q1 + q2))\n",
    "        s_g_split = torch.split(alpha * v_i, sections)\n",
    "\n",
    "        s_g = []\n",
    "        for session in s_g_split:\n",
    "            s_g_session = torch.sum(session, dim=0)\n",
    "            s_g.append(s_g_session)\n",
    "        s_g = torch.stack(s_g)\n",
    "\n",
    "        # (7)\n",
    "        s_l = v_n\n",
    "        s_h = self.W_3(torch.cat([s_l, s_g], dim=-1))\n",
    "\n",
    "        # (8)\n",
    "        z = torch.mm(self.embedding.weight, s_h.T).T\n",
    "        return z"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the hyperparameters.\n",
    "# Code taken from 2021 Fall CS224W Colab assignments.\n",
    "args = {\n",
    "    'batch_size': 100,\n",
    "    'hidden_dim': 32,\n",
    "    'epochs': 100,\n",
    "    'l2_penalty': 0.00001,\n",
    "    'weight_decay': 0.1,\n",
    "    'step': 30,\n",
    "    'lr': 0.001,\n",
    "    'num_items': 466868}\n",
    "\n",
    "class objectview(object): # 이게뭐여\n",
    "    def __init__(self, d): \n",
    "        self.__dict__ = d\n",
    "\n",
    "args = objectview(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(args):\n",
    "    # Prepare data pipeline\n",
    "    train_dataset = GraphDataset('./', 'train')\n",
    "    train_loader = pyg_data.DataLoader(train_dataset,\n",
    "                                       batch_size=args.batch_size,\n",
    "                                       shuffle=False,\n",
    "                                       drop_last=True)\n",
    "    val_dataset = GraphDataset('./', 'val')\n",
    "    val_loader = pyg_data.DataLoader(val_dataset,\n",
    "                                     batch_size=args.batch_size,\n",
    "                                     shuffle=False,\n",
    "                                     drop_last=True)\n",
    "\n",
    "    # Build model\n",
    "    model = SRGNN(args.hidden_dim, args.num_items).to('cuda')\n",
    "\n",
    "    # Get training components\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr=args.lr,\n",
    "                                 weight_decay=args.l2_penalty)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer,\n",
    "                                          step_size=args.step,\n",
    "                                          gamma=args.weight_decay)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    # Train\n",
    "    losses = []\n",
    "    test_accs = []\n",
    "    top_k_accs = []\n",
    "\n",
    "    best_acc = 0\n",
    "    best_model = None\n",
    "\n",
    "    for epoch in range(args.epochs):\n",
    "        total_loss = 0\n",
    "        model.train()\n",
    "        for _, batch in enumerate(tqdm(train_loader)):\n",
    "            batch.to('cuda')\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            pred = model(batch)\n",
    "            label = batch.y\n",
    "            loss = criterion(pred, label)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item() * batch.num_graphs\n",
    "\n",
    "        total_loss /= len(train_loader.dataset)\n",
    "        losses.append(total_loss)\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if epoch % 1 == 0:\n",
    "          test_acc, top_k_acc = test(val_loader, model, is_validation=True)\n",
    "          print(test_acc)\n",
    "          test_accs.append(test_acc)\n",
    "          top_k_accs.append(top_k_acc)\n",
    "          if test_acc > best_acc:\n",
    "            best_acc = test_acc\n",
    "            best_model = copy.deepcopy(model)\n",
    "        else:\n",
    "          test_accs.append(test_accs[-1])\n",
    "  \n",
    "    return test_accs, top_k_accs, losses, best_model, best_acc, val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(loader, test_model, is_validation=False, save_model_preds=False):\n",
    "    test_model.eval()\n",
    "\n",
    "    # Define K for Hit@K metrics.\n",
    "    k = 20\n",
    "    correct = 0\n",
    "    top_k_correct = 0\n",
    "\n",
    "    for _, data in enumerate(tqdm(loader)):\n",
    "        data.to('cuda')\n",
    "        with torch.no_grad():\n",
    "            # max(dim=1) returns values, indices tuple; only need indices\n",
    "            score = test_model(data)\n",
    "            pred = score.max(dim=1)[1]\n",
    "            label = data.y\n",
    "\n",
    "        if save_model_preds:\n",
    "          data = {}\n",
    "          data['pred'] = pred.view(-1).cpu().detach().numpy()\n",
    "          data['label'] = label.view(-1).cpu().detach().numpy()\n",
    "\n",
    "          df = pd.DataFrame(data=data)\n",
    "          # Save locally as csv\n",
    "          df.to_csv('pred.csv', sep=',', index=False)\n",
    "            \n",
    "        correct += pred.eq(label).sum().item()\n",
    "\n",
    "        # We calculate Hit@K accuracy only at test time.\n",
    "        if not is_validation:\n",
    "            score = score.cpu().detach().numpy()\n",
    "            for row in range(pred.size(0)):\n",
    "                top_k_pred = np.argpartition(score[row], -k)[-k:]\n",
    "                if label[row].item() in top_k_pred:\n",
    "                    top_k_correct += 1\n",
    "    \n",
    "    if not is_validation:\n",
    "        return correct / len(loader), top_k_correct / len(loader)\n",
    "    else:\n",
    "        return correct / len(loader), 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.\\\\raw/train.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\SeoJeongBin\\Desktop\\Code\\Recommendation\\GNN\\SR-GNN.ipynb Cell 29\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m test_accs, top_k_accs, losses, best_model, best_acc, test_loader \u001b[39m=\u001b[39m train(args) \n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(test_accs, top_k_accs)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mMaximum test set accuracy: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\u001b[39mmax\u001b[39m(test_accs)))\n",
      "\u001b[1;32mc:\\Users\\SeoJeongBin\\Desktop\\Code\\Recommendation\\GNN\\SR-GNN.ipynb Cell 29\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(args)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(args):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m     \u001b[39m# Prepare data pipeline\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     train_dataset \u001b[39m=\u001b[39m GraphDataset(\u001b[39m'\u001b[39;49m\u001b[39m./\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     train_loader \u001b[39m=\u001b[39m pyg_data\u001b[39m.\u001b[39mDataLoader(train_dataset,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m                                        batch_size\u001b[39m=\u001b[39margs\u001b[39m.\u001b[39mbatch_size,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m                                        shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m                                        drop_last\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     val_dataset \u001b[39m=\u001b[39m GraphDataset(\u001b[39m'\u001b[39m\u001b[39m./\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mval\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32mc:\\Users\\SeoJeongBin\\Desktop\\Code\\Recommendation\\GNN\\SR-GNN.ipynb Cell 29\u001b[0m in \u001b[0;36mGraphDataset.__init__\u001b[1;34m(self, root, file_name, transform, pre_transform)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root, file_name, transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, pre_transform\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfile_name \u001b[39m=\u001b[39m file_name\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mload(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_paths[\u001b[39m0\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\SeoJeongBin\\miniconda3\\envs\\kotorch\\lib\\site-packages\\torch_geometric\\data\\in_memory_dataset.py:56\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, root: Optional[\u001b[39mstr\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     53\u001b[0m              transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     54\u001b[0m              pre_transform: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     55\u001b[0m              pre_filter: Optional[Callable] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m):\n\u001b[1;32m---> 56\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__init__\u001b[39;49m(root, transform, pre_transform, pre_filter)\n\u001b[0;32m     57\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     58\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mslices \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\SeoJeongBin\\miniconda3\\envs\\kotorch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:87\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[1;34m(self, root, transform, pre_transform, pre_filter)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_download()\n\u001b[0;32m     86\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mprocess\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m---> 87\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process()\n",
      "File \u001b[1;32mc:\\Users\\SeoJeongBin\\miniconda3\\envs\\kotorch\\lib\\site-packages\\torch_geometric\\data\\dataset.py:170\u001b[0m, in \u001b[0;36mDataset._process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    167\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcessing...\u001b[39m\u001b[39m'\u001b[39m, file\u001b[39m=\u001b[39msys\u001b[39m.\u001b[39mstderr)\n\u001b[0;32m    169\u001b[0m makedirs(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir)\n\u001b[1;32m--> 170\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprocess()\n\u001b[0;32m    172\u001b[0m path \u001b[39m=\u001b[39m osp\u001b[39m.\u001b[39mjoin(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprocessed_dir, \u001b[39m'\u001b[39m\u001b[39mpre_transform.pt\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    173\u001b[0m torch\u001b[39m.\u001b[39msave(_repr(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpre_transform), path)\n",
      "\u001b[1;32mc:\\Users\\SeoJeongBin\\Desktop\\Code\\Recommendation\\GNN\\SR-GNN.ipynb Cell 29\u001b[0m in \u001b[0;36mGraphDataset.process\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprocess\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     raw_data_file \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_dir\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mraw_file_names[\u001b[39m0\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(raw_data_file, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mas\u001b[39;00m f:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m         sessions \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39mload(f)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/SeoJeongBin/Desktop/Code/Recommendation/GNN/SR-GNN.ipynb#X56sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     data_list \u001b[39m=\u001b[39m []\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.\\\\raw/train.txt'"
     ]
    }
   ],
   "source": [
    "test_accs, top_k_accs, losses, best_model, best_acc, test_loader = train(args) \n",
    "\n",
    "print(test_accs, top_k_accs)\n",
    "print(\"Maximum test set accuracy: {0}\".format(max(test_accs)))\n",
    "print(\"Minimum loss: {0}\".format(min(losses)))\n",
    "\n",
    "# plt.title(dataset.name)\n",
    "plt.plot(losses, label=\"training loss\" + \" - \")\n",
    "plt.plot(test_accs, label=\"test accuracy\" + \" - \")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('kotorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e394b0e5950b2ed9ac02d3d0f43da50df004fa03f183c9ffe2862d4a06a95d21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
